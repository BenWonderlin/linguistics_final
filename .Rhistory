group = c()
task = c()
coef = c()
error = c()
# fit models for experiments on English data
groups = c("control_partial", "control_all", "control_partial_exclude")
tasks = c("written", "auditory", "alien")
for(group_idx in 1:length(groups)){
for(task_idx in 1:length(tasks)){
# get right data for task
tmp_data = s1_data %>%
filter(task == tasks[task_idx])
if (task_idx == 3){
tmp_data = tmp_data %>%
mutate(rating = scales::rescale(rating, to = c(0, 10)))
}
# control for right variables (according to group)
if(group_idx == 1){
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + concreteness + phonemes + totalMorphemes + babyAVG + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
}
else if (group_idx == 2){
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + concreteness + phonemes + totalMorphemes + babyAVG + systematicity + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
}
else{
tmp_data = subset(tmp_data, lexicalCategory != "onomatopoeia and interjections")
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + concreteness + phonemes + totalMorphemes + babyAVG + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
}
# fit model and append coefs to array
model = lmer(residRating ~ X30mos + (1|subjCode), data = tmp_data)
model_summary = summary(model)
group = c(group, groups[group_idx])
task = c(task, tasks[task_idx])
coef = c(coef, model_summary$coefficients[2, 1])
error = c(error, model_summary$coefficients[2, 2])
}
}
# fit models for experiments on English data (same as prev. block, but with different data)
groups = c("control_partial", "control_partial_exclude")
tasks = c("infinitive", "conjugated")
for(group_idx in 1:length(groups)){
for(task_idx in 1:length(tasks)){
tmp_data = s2_data %>%
filter(task == tasks[task_idx])
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + phonemes + morphemes + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
if (group_idx == 1){
tmp_data$resid_rating = resid(
lmer(
rating ~ logFreq + phonemes + morphemes + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
}
else {
tmp_data = subset(tmp_data, lexicalCategory != "onomatopoeia and interjections")
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + phonemes + morphemes + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
}
model = lmer(residRating ~ X30mos + (1|subjCode), data = tmp_data)
model_summary = summary(model)
group = c(group, groups[group_idx])
task = c(task, tasks[task_idx])
coef = c(coef, model_summary$coefficients[2, 1])
error = c(error, model_summary$coefficients[2, 2])
}
}
# pad cols to make up for missing experiments
group = c( group, "control_all", "control_all" )
task = c( task, "infinitive", "conjugated" )
coef = c( coef, 0, 0 )
error = c( error, 0, 0 )
figure_two_data = tibble(group, task, coef, error)
figure_two_data = figure_two_data %>%
mutate(group = factor(group, levels = c("control_partial", "control_all", "control_partial_exclude"))) %>%
mutate(task = factor(task, levels = c("written", "auditory", "alien", "infinitive", "conjugated")))
head(figure_two_data)
ggplot(figure_two_data,
aes(fill = task, x = group, y = coef, ymin = coef - error, ymax = coef + error)) +
geom_bar(position = "dodge", stat = "identity", color = "Black" ) +
geom_errorbar(position = "dodge") +
labs(x = "Group", y = "Relationship between AoA and Iconicity", title = "Figure Two Replication") +
scale_fill_manual(values = brewer.pal(5, "Blues"))
english_aoa = s1_data %>%
filter(task == "written") %>%
dplyr::select(word, rating, X30mos) %>%
group_by(word) %>%
summarize(english_iconicity = mean(rating), english_aoa = mean(X30mos))
spanish_aoa = s2_data %>%
dplyr::select(word, rating, X30mos, english) %>%
group_by(word) %>%
summarize(spanish_iconicity = mean(rating), spanish_aoa = mean(X30mos), english = max(english))
paired_data = inner_join(english_aoa, spanish_aoa, by = c("word" = "english"))
head(paired_data)
lm1 = lm(english_iconicity ~ english_aoa + spanish_aoa, data = paired_data)
lm2 = lm(spanish_iconicity ~ english_aoa + spanish_aoa, data = paired_data)
iconicity = c("english", "english", "spanish", "spanish")
AoA = c("english", "spanish", "english", "spanish")
coef = c( summary(lm1)$coefficients[2:3, 1], summary(lm2)$coefficients[2:3, 1] )
error = c( summary(lm1)$coefficients[2:3, 2], summary(lm1)$coefficients[2:3, 2])
figure_three_data = tibble(AoA, iconicity, coef, error)
head(figure_three_data)
ggplot(figure_three_data,
aes(fill = AoA, x = iconicity, y = coef, ymin = coef - error, ymax = coef + error)) +
geom_bar(position = "dodge", stat = "identity", color = "Black" ) +
geom_errorbar(position = "dodge") +
labs(x = "Iconicity", y = "Relationship between AoA and Iconicity", title = "Figure Three Replication") +
scale_fill_manual(values = brewer.pal(3, "Blues"))
plot_line_f4 = function(data, exp_num){
ggplot(tmp_data, aes(x = X30mos, y = residRating)) +
stat_smooth(method = "lm", level = 0.68) +
xlim(20, 100) +
labs(title = sprintf("Experiment %d", exp_num), x = "% of Children Saying at 30mos", y = "Residual Iconicity")
}
tmp_data = s1_data %>%
filter(task == "written")
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + concreteness + phonemes + totalMorphemes + babyAVG + concreteness + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
pl1 = plot_line_f4(tmp_data, 1)
tmp_data = s1_data %>%
filter(task == "auditory")
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + concreteness + phonemes + totalMorphemes + babyAVG + concreteness + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
pl2 = plot_line_f4(tmp_data, 2)
tmp_data = s1_data %>%
filter(task == "alien")
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + concreteness + phonemes + totalMorphemes + babyAVG + concreteness + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
pl3 = plot_line_f4(tmp_data, 3)
tmp_data = s2_data %>%
filter(task == "infinitive")
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + phonemes + morphemes + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
pl4 = plot_line_f4(tmp_data, 4)
tmp_data = s2_data %>%
filter(task == "conjugated")
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + phonemes + morphemes + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
pl5 = plot_line_f4(tmp_data, 5)
layout = "
AB
C#
DE
"
pl1 + pl2 + pl3 + pl4 + pl5 + plot_layout(design = layout) + plot_annotation(title = "Figure Four Replication")
extension_data = s1_data %>%
drop_na() %>%
dplyr::select(word, lexicalCategory, X30mos, phonemes, concreteness, logFreq, systematicity, babyAVG) %>%
group_by(word) %>%
summarize(
systematicity = mean(systematicity),
lexicalCategory = max(lexicalCategory),
X30mos = mean(X30mos),
phonemes = mean(phonemes),
concreteness = mean(concreteness),
logFreq = mean(logFreq),
babyAVG = mean(babyAVG)
)
feature_data = extension_data %>%
dplyr::select(lexicalCategory, X30mos, phonemes, concreteness, logFreq, babyAVG)
head(feature_data)
feature_data %>%
ggpairs(., lower = list(continuous = wrap("smooth_loess", size = 0.5)))
extension_lm_null = extension_data %>%
lm(systematicity ~ lexicalCategory + logFreq ,
data = .)
extension_lm = extension_data %>%
lm(systematicity ~ lexicalCategory + logFreq + X30mos ,
data = .)
par(mfrow = c(2, 2))
plot(extension_lm_null)
par(mfrow = c(2, 2))
plot(extension_lm)
vif(extension_lm)
collin.fnc(extension_data %>% dplyr::select(X30mos, logFreq))$cnumber
anova(extension_lm_null, extension_lm)
extension_data$resids = resid( extension_lm_null )
extension_data %>%
ggplot(aes(x = X30mos, y = resids)) +
geom_point() +
stat_smooth(method = "lm") +
labs(title = "Residual Systematicity vs. Age of Acquisition", x = "Proportion of Children Saying Word at 30mos", y = "Residual Systematicity")
library("tidyverse")
library("RColorBrewer")
library("languageR")
library("GGally")
library("car")
library("arm")
library("patchwork")
s1_data = read_csv("./data/S1_Data.csv")
s2_data = read_csv("./data/S2_Data.csv")
compute_error = function(rating) {
return( sd(rating) / sqrt(length(rating)) )
}
task_one = s1_data %>%
filter( task == "alien" ) %>%
mutate( rating = scales::rescale(rating, to = c(0, 5) )) %>%
group_by(task, lexicalCategory) %>%
summarize(mean = mean(rating), error = compute_error(rating), .groups = 'drop' )
task_two_and_three = s1_data %>%
filter( task != "alien" ) %>%
group_by(task, lexicalCategory) %>%
summarize(mean = mean(rating), error = compute_error(rating), .groups = 'drop' )
task_three_and_four  = s2_data %>%
group_by(task, lexicalCategory) %>%
summarize(mean = mean(rating), error = compute_error(rating), .groups = 'drop' )
figure_one_data = bind_rows( task_one, task_two_and_three, task_three_and_four) %>%
mutate(task = factor(task, levels = c("written", "auditory", "alien", "infinitive", "conjugated"))) %>%
mutate(lexicalCategory = factor(lexicalCategory, levels = c("onomatopoeia and interjections", "adjective", "verb", "noun", "function")))
head(figure_one_data)
ggplot(figure_one_data,
aes(fill = task, x = lexicalCategory, y = mean, ymin = mean - error, ymax = mean + error)) +
geom_bar(position = "dodge", stat = "identity", color = "Black" ) +
geom_errorbar(position = "dodge") +
labs(x = "Lexical Category", y = "Mean Rating", title = "Figure One Replication") +
scale_fill_manual(values = brewer.pal(5, "Blues"))
# define table columns
group = c()
task = c()
coef = c()
error = c()
# fit models for experiments on English data
groups = c("control_partial", "control_all", "control_partial_exclude")
tasks = c("written", "auditory", "alien")
for(group_idx in 1:length(groups)){
for(task_idx in 1:length(tasks)){
# get right data for task
tmp_data = s1_data %>%
filter(task == tasks[task_idx])
if (task_idx == 3){
tmp_data = tmp_data %>%
mutate(rating = scales::rescale(rating, to = c(0, 10)))
}
# control for right variables (according to group)
if(group_idx == 1){
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + concreteness + phonemes + totalMorphemes + babyAVG + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
}
else if (group_idx == 2){
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + concreteness + phonemes + totalMorphemes + babyAVG + systematicity + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
}
else{
tmp_data = subset(tmp_data, lexicalCategory != "onomatopoeia and interjections")
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + concreteness + phonemes + totalMorphemes + babyAVG + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
}
# fit model and append coefs to array
model = lmer(residRating ~ X30mos + (1|subjCode), data = tmp_data)
model_summary = summary(model)
group = c(group, groups[group_idx])
task = c(task, tasks[task_idx])
coef = c(coef, model_summary$coefficients[2, 1])
error = c(error, model_summary$coefficients[2, 2])
}
}
# fit models for experiments on English data (same as prev. block, but with different data)
groups = c("control_partial", "control_partial_exclude")
tasks = c("infinitive", "conjugated")
for(group_idx in 1:length(groups)){
for(task_idx in 1:length(tasks)){
tmp_data = s2_data %>%
filter(task == tasks[task_idx])
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + phonemes + morphemes + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
if (group_idx == 1){
tmp_data$resid_rating = resid(
lmer(
rating ~ logFreq + phonemes + morphemes + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
}
else {
tmp_data = subset(tmp_data, lexicalCategory != "onomatopoeia and interjections")
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + phonemes + morphemes + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
}
model = lmer(residRating ~ X30mos + (1|subjCode), data = tmp_data)
model_summary = summary(model)
group = c(group, groups[group_idx])
task = c(task, tasks[task_idx])
coef = c(coef, model_summary$coefficients[2, 1])
error = c(error, model_summary$coefficients[2, 2])
}
}
# pad cols to make up for missing experiments
group = c( group, "control_all", "control_all" )
task = c( task, "infinitive", "conjugated" )
coef = c( coef, 0, 0 )
error = c( error, 0, 0 )
figure_two_data = tibble(group, task, coef, error)
figure_two_data = figure_two_data %>%
mutate(group = factor(group, levels = c("control_partial", "control_all", "control_partial_exclude"))) %>%
mutate(task = factor(task, levels = c("written", "auditory", "alien", "infinitive", "conjugated")))
head(figure_two_data)
ggplot(figure_two_data,
aes(fill = task, x = group, y = coef, ymin = coef - error, ymax = coef + error)) +
geom_bar(position = "dodge", stat = "identity", color = "Black" ) +
geom_errorbar(position = "dodge") +
labs(x = "Group", y = "Relationship between AoA and Iconicity", title = "Figure Two Replication") +
scale_fill_manual(values = brewer.pal(5, "Blues"))
english_aoa = s1_data %>%
filter(task == "written") %>%
dplyr::select(word, rating, X30mos) %>%
group_by(word) %>%
summarize(english_iconicity = mean(rating), english_aoa = mean(X30mos))
spanish_aoa = s2_data %>%
dplyr::select(word, rating, X30mos, english) %>%
group_by(word) %>%
summarize(spanish_iconicity = mean(rating), spanish_aoa = mean(X30mos), english = max(english))
paired_data = inner_join(english_aoa, spanish_aoa, by = c("word" = "english"))
head(paired_data)
lm1 = lm(english_iconicity ~ english_aoa + spanish_aoa, data = paired_data)
lm2 = lm(spanish_iconicity ~ english_aoa + spanish_aoa, data = paired_data)
iconicity = c("english", "english", "spanish", "spanish")
AoA = c("english", "spanish", "english", "spanish")
coef = c( summary(lm1)$coefficients[2:3, 1], summary(lm2)$coefficients[2:3, 1] )
error = c( summary(lm1)$coefficients[2:3, 2], summary(lm1)$coefficients[2:3, 2])
figure_three_data = tibble(AoA, iconicity, coef, error)
head(figure_three_data)
ggplot(figure_three_data,
aes(fill = AoA, x = iconicity, y = coef, ymin = coef - error, ymax = coef + error)) +
geom_bar(position = "dodge", stat = "identity", color = "Black" ) +
geom_errorbar(position = "dodge") +
labs(x = "Iconicity", y = "Relationship between AoA and Iconicity", title = "Figure Three Replication") +
scale_fill_manual(values = brewer.pal(3, "Blues"))
plot_line_f4 = function(data, exp_num){
ggplot(tmp_data, aes(x = X30mos, y = residRating)) +
stat_smooth(method = "lm", level = 0.68) +
xlim(20, 100) +
labs(title = sprintf("Experiment %d", exp_num), x = "% of Children Saying Word at 30mos", y = "Residual Iconicity")
}
tmp_data = s1_data %>%
filter(task == "written")
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + concreteness + phonemes + totalMorphemes + babyAVG + concreteness + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
pl1 = plot_line_f4(tmp_data, 1)
tmp_data = s1_data %>%
filter(task == "auditory")
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + concreteness + phonemes + totalMorphemes + babyAVG + concreteness + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
pl2 = plot_line_f4(tmp_data, 2)
tmp_data = s1_data %>%
filter(task == "alien")
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + concreteness + phonemes + totalMorphemes + babyAVG + concreteness + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
pl3 = plot_line_f4(tmp_data, 3)
tmp_data = s2_data %>%
filter(task == "infinitive")
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + phonemes + morphemes + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
pl4 = plot_line_f4(tmp_data, 4)
tmp_data = s2_data %>%
filter(task == "conjugated")
tmp_data$residRating = resid(
lmer(
rating ~ logFreq + phonemes + morphemes + (1|subjCode),
data = tmp_data,
na.action = na.exclude
)
)
pl5 = plot_line_f4(tmp_data, 5)
layout = "
AB
C#
DE
"
pl1 + pl2 + pl3 + pl4 + pl5 + plot_layout(design = layout) + plot_annotation(title = "Figure Four Replication")
extension_data = s1_data %>%
drop_na() %>%
dplyr::select(word, lexicalCategory, X30mos, phonemes, concreteness, logFreq, systematicity, babyAVG) %>%
group_by(word) %>%
summarize(
systematicity = mean(systematicity),
lexicalCategory = max(lexicalCategory),
X30mos = mean(X30mos),
phonemes = mean(phonemes),
concreteness = mean(concreteness),
logFreq = mean(logFreq),
babyAVG = mean(babyAVG)
)
feature_data = extension_data %>%
dplyr::select(lexicalCategory, X30mos, phonemes, concreteness, logFreq, babyAVG)
head(feature_data)
feature_data %>%
ggpairs(., lower = list(continuous = wrap("smooth_loess", size = 0.5)))
extension_lm_null = extension_data %>%
lm(systematicity ~ lexicalCategory + logFreq ,
data = .)
extension_lm = extension_data %>%
lm(systematicity ~ lexicalCategory + logFreq + X30mos ,
data = .)
par(mfrow = c(2, 2))
plot(extension_lm_null)
par(mfrow = c(2, 2))
plot(extension_lm)
vif(extension_lm)
collin.fnc(extension_data %>% dplyr::select(X30mos, logFreq))$cnumber
anova(extension_lm_null, extension_lm)
extension_data$resids = resid( extension_lm_null )
extension_data %>%
ggplot(aes(x = X30mos, y = resids)) +
geom_point() +
stat_smooth(method = "lm") +
labs(title = "Residual Systematicity vs. Age of Acquisition", x = "Proportion of Children Saying Word at 30mos", y = "Residual Systematicity")
extension_data$resids = resid( extension_lm_null )
extension_data %>%
ggplot(aes(x = X30mos, y = resids)) +
geom_point() +
stat_smooth(method = "lm") +
labs(title = "Residual Systematicity vs. Age of Acquisition", x = "% of Children Saying Word at 30mos", y = "Residual Systematicity")
<br><br>
